{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83c7b66f-8265-431a-98bd-741bdec52590",
   "metadata": {},
   "source": [
    "# STABLE DIFFUSION IMPLEMENTATION USING CELEBA DATASET "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969b6157-59f7-4e76-924f-7a97fd7441f2",
   "metadata": {},
   "source": [
    "### SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac666e7-cd71-4a4f-aa25-5b93f2584d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import functools\n",
    "from tqdm import tqdm, trange\n",
    "import torch.multiprocessing\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.datasets import CelebA\n",
    "from torchvision.transforms import ToTensor, CenterCrop, Resize, Compose, Normalize\n",
    "import math\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import MultiplicativeLR, LambdaLR\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "from StableDiff_UNet_model import UNet_SD, load_pipe_into_our_UNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bbbe84-15b0-419a-a92b-a3918ccb6e20",
   "metadata": {},
   "source": [
    "### TRANSFORMATIONS SETUP AND DATASET LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d93e5aa-a672-42ea-b641-6e82462483a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = Compose( #initializes a sequence of transformations.\n",
    "    Resize(32),\n",
    "    CenterCrop(32),\n",
    "    ToTensor(),\n",
    "    Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "dataset_rsz = CelebA(\"ttoisd\", target_type=[\"attr\"], transform=tfm, download=True)#Initializing the Dataset with Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13be8d26-473c-462d-8c20-8aa6f1b1d3a6",
   "metadata": {},
   "source": [
    "### DATA PREPARATION FOR TRAINING/EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3832a966-30f6-43d6-8dc5-fd1c5a5f2d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset_rsz, batch_size=64, num_workers=8, shuffle=False)\n",
    "x_col = []\n",
    "y_col = []\n",
    "for xs, ys in tqdm(dataloader):#Iterating Through DataLoader and Collecting Data\n",
    "  x_col.append(xs)\n",
    "  y_col.append(ys)\n",
    "x_col = torch.concat(x_col, dim=0)\n",
    "y_col = torch.concat(y_col, dim=0)\n",
    "print(x_col.shape)\n",
    "print(y_col.shape)\n",
    "\n",
    "nantoken = 40 #placeholder or filler in the sequence tensor yseq_data.\n",
    "maxlen = (y_col.sum(dim=1)).max()\n",
    "yseq_data = torch.ones(y_col.size(0), maxlen, dtype=int).fill_(nantoken)\n",
    "\n",
    "saved_dataset = TensorDataset(x_col, yseq_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c020bd2-4278-4bc2-b253-44ca0f108074",
   "metadata": {},
   "source": [
    "### CALCULATION-STANDRAD DEVIATION & DIFFUSION COEFFICIENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f085a5-0918-444a-8b0b-219d9905897a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "def marginal_prob_std(t, sigma):#calculates a standard deviation related to the marginal probability.\n",
    "    t = torch.tensor(t, device=device)\n",
    "    return torch.sqrt((sigma ** (2 * t) - 1.) / 2. / math.log(sigma))\n",
    "\n",
    "def diffusion_coeff(t, sigma): #calculates a diffusion coefficient.\n",
    "    return torch.tensor(sigma ** t, device=device)\n",
    "\n",
    "sigma = 25.0  # @param {'type':'number'}-> sigma is a parameter that can be modified or adjusted.\n",
    "marginal_prob_std_fn = functools.partial(marginal_prob_std, sigma=sigma)\n",
    "diffusion_coeff_fn = functools.partial(diffusion_coeff, sigma=sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a61698a-b050-4f73-897a-a51c4be02b3b",
   "metadata": {},
   "source": [
    "### TRAINING LOSS FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603b905a-19bf-498b-bc01-296fcf700639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn_cond(model, x, y, marginal_prob_std, eps=1e-5):\n",
    "    \"\"\"The loss function for training score-based generative models.\n",
    "\n",
    "    Args:\n",
    "    model: A PyTorch model instance that represents a\n",
    "      time-dependent score-based model.\n",
    "    x: A mini-batch of training data.\n",
    "    marginal_prob_std: A function that gives the standard deviation of\n",
    "      the perturbation kernel.\n",
    "    eps: A tolerance value for numerical stability.\n",
    "    \"\"\"\n",
    "    random_t = torch.rand(x.shape[0], device=x.device) * (1. - eps) + eps  #Creates a tensor of random numbers between 0 and 1, with the same number of elements as there are samples in the mini-batch x\n",
    "    z = torch.randn_like(x)              #Generates Gaussian (normal) noise with the same shape as x\n",
    "    std = marginal_prob_std(random_t) #Calculates the standard deviation for each sample in the batch \n",
    "    perturbed_x = x + z * std[:, None, None, None]   #Adds noise to the data x where z is scaled by the computed standard deviations std\n",
    "    score = model(perturbed_x, random_t, cond=y, output_dict=False)\n",
    "    loss = torch.mean(torch.sum((score * std[:, None, None, None] + z)**2, dim=(1,2,3)))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb0f664-5351-4379-9060-c7fde0f327b9",
   "metadata": {},
   "source": [
    "### SAMPLING USING EULER-MARUYAMA METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2ab0d3-5d0a-496e-9195-325ebe996c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Euler_Maruyama_sampler(score_model,  \n",
    "                           marginal_prob_std,\n",
    "                           diffusion_coeff,\n",
    "                           batch_size=64,\n",
    "                           x_shape=(1, 28, 28),\n",
    "                           num_steps=500,\n",
    "                           device='cuda',\n",
    "                           eps=1e-3,\n",
    "                           y=None):\n",
    "    t = torch.ones(batch_size, device=device)\n",
    "    init_x = torch.randn(batch_size, *x_shape, device=device) \\\n",
    "             * marginal_prob_std(t)[:, None, None, None]\n",
    "    time_steps = torch.linspace(1., eps, num_steps, device=device)\n",
    "    step_size = time_steps[0] - time_steps[1]\n",
    "    x = init_x\n",
    "    with torch.no_grad():\n",
    "        for time_step in tqdm(time_steps):\n",
    "            batch_time_step = torch.ones(batch_size, device=device) * time_step\n",
    "            g = diffusion_coeff(batch_time_step)\n",
    "            mean_x = x + (g ** 2)[:, None, None, None] * score_model(x, batch_time_step, cond=y, output_dict=False) * step_size\n",
    "            x = mean_x + torch.sqrt(step_size) * g[:, None, None, None] * torch.randn_like(x)\n",
    "            # Do not include any noise in the last sampling step.\n",
    "    return mean_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e360296-530e-4b24-b456-2a50d877a650",
   "metadata": {},
   "source": [
    "### TRAINING A SCORE-BASED GENERATIVE MODEL  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd70e25-5f08-4778-9071-9508164935a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_score_model(score_model, cond_embed, dataset, lr, n_epochs, batch_size, ckpt_name,\n",
    "                      marginal_prob_std_fn=marginal_prob_std_fn,\n",
    "                      lr_scheduler_fn=lambda epoch: max(0.2, 0.98 ** epoch),\n",
    "                      device=\"cuda\",\n",
    "                      callback=None): # resume=False,\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    optimizer = Adam([*score_model.parameters(), *cond_embed.parameters()], lr=lr)\n",
    "    scheduler = LambdaLR(optimizer, lr_lambda=lr_scheduler_fn)\n",
    "    tqdm_epoch = trange(n_epochs)\n",
    "    for epoch in tqdm_epoch: #Loop over each epoch with a progress bar\n",
    "        score_model.train()\n",
    "        avg_loss = 0.\n",
    "        num_items = 0\n",
    "        batch_tqdm = tqdm(data_loader)\n",
    "        for x, y in batch_tqdm:\n",
    "            x = x.to(device)\n",
    "            y_emb = cond_embed(y.to(device))  #Moves the conditional data to the device and embeds it using cond_embed.\n",
    "            loss = loss_fn_cond(score_model, x, y_emb, marginal_prob_std_fn)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()  #Computes gradients of the loss with respect to model parameters.\n",
    "            optimizer.step()\n",
    "            avg_loss += loss.item() * x.shape[0]\n",
    "            num_items += x.shape[0]\n",
    "            batch_tqdm.set_description(\"Epoch %d, loss %.4f\" % (epoch, avg_loss / num_items))\n",
    "        scheduler.step()\n",
    "        lr_current = scheduler.get_last_lr()[0]\n",
    "        print('{} Average Loss: {:5f} lr {:.1e}'.format(epoch, avg_loss / num_items, lr_current))\n",
    "        # Print the averaged training loss so far.\n",
    "        tqdm_epoch.set_description('Average Loss: {:5f}'.format(avg_loss / num_items))\n",
    "        # Update the checkpoint after each epoch of training.\n",
    "        torch.save(score_model.state_dict(), f'fort2/ckpt_{ckpt_name}.pth')\n",
    "        torch.save(cond_embed.state_dict(),\n",
    "                   f'fort2/ckpt_{ckpt_name}_cond_embed.pth')\n",
    "        if callback is not None:\n",
    "            score_model.eval()\n",
    "            callback(score_model, epoch, ckpt_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5fb11d-fba7-47eb-8d62-67384987fb14",
   "metadata": {},
   "source": [
    "### GENERATING AND SAVING SAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b289aff-035d-4b97-925e-2daa8e1ddfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sample_callback(score_model, epocs, ckpt_name):\n",
    "    sample_batch_size = 64\n",
    "    num_steps = 250\n",
    "    y_samp = yseq_data[:sample_batch_size, :]\n",
    "    y_emb = cond_embed(y_samp.cuda())\n",
    "    sampler = Euler_Maruyama_sampler\n",
    "    samples = sampler(score_model,\n",
    "                      marginal_prob_std_fn,\n",
    "                      diffusion_coeff_fn,\n",
    "                      sample_batch_size,\n",
    "                      x_shape=(3, 32, 32),\n",
    "                      num_steps=num_steps,\n",
    "                      device=device,\n",
    "                      y=y_emb, )\n",
    "    denormalize = Normalize([-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
    "                        [1/0.229, 1/0.224, 1/0.225])\n",
    "    samples = denormalize(samples).clamp(0.0, 1.0)\n",
    "    sample_grid = make_grid(samples, nrow=int(math.sqrt(sample_batch_size)))\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(sample_grid.permute(1, 2, 0).cpu(), vmin=0., vmax=1.)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"fort2/samples_{ckpt_name}_{epocs}.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aadd78a-a080-48e8-84e3-546e0bdd2caa",
   "metadata": {},
   "source": [
    "### SETTING UP A STABLE DIFFUSION U-NET MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bef0a8c-1269-46c7-ac38-4f49014d9706",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_face = UNet_SD(in_channels=3,\n",
    "                    base_channels=128,\n",
    "                    time_emb_dim=256,\n",
    "                    context_dim=256,\n",
    "                    multipliers=(1, 1, 2),\n",
    "                    attn_levels=(1, 2, ),\n",
    "                    nResAttn_block=1,\n",
    "                    )\n",
    "cond_embed = nn.Embedding(40 + 1, 256, padding_idx=40).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7aa9e4-3c84-419d-bd2f-552dd740442d",
   "metadata": {},
   "source": [
    "### MODEL TRAINING AND SAVING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c3576a-1b6d-4425-8906-e0414c80cff4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.save(unet_face.state_dict(), \"fort2/SD_unet_face.pt\",)\n",
    "unet_face(torch.randn(1, 3, 64, 64).cuda(), time_steps=torch.rand(1).cuda(),\n",
    "          cond=torch.randn(1, 20, 256).cuda(),\n",
    "          output_dict=False)\n",
    "\n",
    "train_score_model(unet_face, cond_embed, saved_dataset,\n",
    "                  lr=1.5e-4, n_epochs=100, batch_size=256,\n",
    "                  ckpt_name=\"unet_SD_face\", device=device,\n",
    "                  callback=save_sample_callback)\n",
    "\n",
    "save_sample_callback(unet_face, 0, \"unet_SD_face\")\n",
    "torch.save(cond_embed.state_dict(), f'fort2/ckpt_{\"unet_SD_face\"}_cond_embed.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af035dbf-3d4a-4395-b238-2861d7f7ec79",
   "metadata": {},
   "source": [
    "###  DEMONSTRATION OF HOW TO MANIPULATE IMAGE ATTRIBUTES USING A TRAINED MODEL AND GENERATE NEW IMAGES WITH MODIFIED ATTRIBUTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1dbf35-74c5-491f-96ae-423dcb188567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "import math\n",
    "from tqdm import tqdm, trange\n",
    "import torch.multiprocessing\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.datasets import CelebA\n",
    "from torchvision.transforms import ToTensor, CenterCrop, Resize, Compose, Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca949586-3ed9-4918-b730-6bfbdc744237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to calculate marginal probability and diffusion coefficient\n",
    "def marginal_prob_std(t, sigma):\n",
    "    t = torch.tensor(t, device=device)\n",
    "    return torch.sqrt((sigma ** (2 * t) - 1.) / 2. / math.log(sigma))\n",
    "\n",
    "def diffusion_coeff(t, sigma):\n",
    "    return torch.tensor(sigma ** t, device=device)\n",
    "\n",
    "sigma = 25.0\n",
    "marginal_prob_std_fn = functools.partial(marginal_prob_std, sigma=sigma)\n",
    "diffusion_coeff_fn = functools.partial(diffusion_coeff, sigma=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e9789d-afb4-40e7-a0b0-12607d3a2c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euler-Maruyama sampler for generating samples\n",
    "def Euler_Maruyama_sampler(score_model, marginal_prob_std, diffusion_coeff, batch_size=64, x_shape=(3, 32, 32), num_steps=500, device='cuda', eps=1e-3, y=None):\n",
    "    t = torch.ones(batch_size, device=device)\n",
    "    init_x = torch.randn(batch_size, *x_shape, device=device) * marginal_prob_std(t)[:, None, None, None]\n",
    "    time_steps = torch.linspace(1., eps, num_steps, device=device)\n",
    "    step_size = time_steps[0] - time_steps[1]\n",
    "    x = init_x\n",
    "    with torch.no_grad():\n",
    "        for time_step in tqdm(time_steps):\n",
    "            batch_time_step = torch.ones(batch_size, device=device) * time_step\n",
    "            g = diffusion_coeff(batch_time_step)\n",
    "            mean_x = x + (g ** 2)[:, None, None, None] * score_model(x, batch_time_step, cond=y, output_dict=False) * step_size\n",
    "            x = mean_x + torch.sqrt(step_size) * g[:, None, None, None] * torch.randn_like(x)\n",
    "    return mean_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2da684-3bef-4c19-a5a4-cc88d015d33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model and embedding\n",
    "device = 'cuda'\n",
    "unet_face = UNet_SD(in_channels=3, base_channels=128, time_emb_dim=256, context_dim=256, multipliers=(1, 1, 2), attn_levels=(1, 2), nResAttn_block=1).to(device)\n",
    "cond_embed = nn.Embedding(40 + 1, 256, padding_idx=40).to(device)\n",
    "\n",
    "unet_face.load_state_dict(torch.load('fort2/ckpt_unet_SD_face.pth'))\n",
    "cond_embed.load_state_dict(torch.load('fort2/ckpt_unet_SD_face_cond_embed.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d27775c-3d59-4fff-9c31-5fc85c253707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations and load CelebA dataset\n",
    "tfm = Compose([Resize(32), CenterCrop(32), ToTensor(), Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "dataset = CelebA(\"ttoisd\", target_type=[\"attr\"], transform=tfm, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc67efb-b398-47bd-8030-6d9652bc88e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a single image and its attributes\n",
    "single_image, single_attr = next(iter(dataloader))\n",
    "single_image = single_image.to(device)\n",
    "single_attr = single_attr.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a00d38f-e99e-4490-9e2d-b5e881baf529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define specific labels for the single image (modify as desired)\n",
    "desired_labels = single_attr.clone()\n",
    "#desired_labels[0, 31] = 0  # Set 'smiling' attribute to False\n",
    "desired_labels[0, 15] = 1# Set 'wearing glasses' attribute to True\n",
    "#desired_labels[0, 8] = 1 # black hair\n",
    "#desired_labels[0, 35] = 1 # wearing hat\n",
    "#desired_labels[0, 39] = 1 # wearing hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f8730f-accd-42d7-96d3-e02ea49e5dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the labels\n",
    "y_emb = cond_embed(desired_labels.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821627cd-3fa0-4e5f-a620-2efe27fabf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate and visualize sample images\n",
    "def generate_and_visualize_samples(model, y_emb, original_image, device='cuda', num_samples=1, num_steps=250):\n",
    "    samples = Euler_Maruyama_sampler(model, marginal_prob_std_fn, diffusion_coeff_fn, num_samples, x_shape=(3, 32, 32), num_steps=num_steps, device=device, y=y_emb)\n",
    "\n",
    "    # Denormalize the samples\n",
    "    denormalize = Normalize([-0.485/0.229, -0.456/0.224, -0.406/0.225], [1/0.229, 1/0.224, 1/0.225])\n",
    "    samples = denormalize(samples).clamp(0.0, 1.0)\n",
    "    \n",
    "    # Visualize the original and generated samples\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    \n",
    "    # Original image\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title('Original Image')\n",
    "    original_image_denorm = denormalize(original_image).clamp(0.0, 1.0)\n",
    "    plt.imshow(original_image_denorm[0].permute(1, 2, 0).cpu(), vmin=0., vmax=1.)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Generated image\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title('Generated Image')\n",
    "    plt.imshow(samples[0].permute(1, 2, 0).cpu(), vmin=0., vmax=1.)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Generate and visualize samples with the desired labels\n",
    "generate_and_visualize_samples(unet_face, y_emb, single_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1323f03-9986-4215-b8dc-b13efa69a499",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''1.5_o_Clock_Shadow,2.Arched_Eyebrows,3.Attractive,4.Bags_Under_Eyes,5.Bald,6.Bangs,7.Big_Lips,8.Big_Nose,9.Black_Hair,10.Blond_Hair,11.Blurry,12.Brown_Hair\n",
    "13.Bushy_Eyebrows,14.Chubby,15.Double_Chin,16.Eyeglasses,17.Goatee,18.Gray_Hair,19.Heavy_Makeup,20.High_Cheekbones,21.Male,22.Mouth_Slightly_Open\n",
    "23.Mustache,24.Narrow_Eyes,25.No_Beard,26.Oval_Face,27.Pale_Skin,28.Pointy_Nose,29.Receding_Hairline,30.Rosy_Cheeks,31.Sideburns,32.Smiling\n",
    "33.Straight_Hair,34.Wavy_Hair,35.Wearing_Earrings,36.Wearing_Hat,37.Wearing_Lipstick,38.Wearing_Necklace,39.Wearing_Necktie,40.Young"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7dbe5a-51ad-4a20-a381-862ab21b92a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import torch\n",
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "import math\n",
    "from tqdm import tqdm, trange\n",
    "import torch.multiprocessing\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from StableDiff_UNet_model import UNet_SD, load_pipe_into_our_UNet\n",
    "from torch.multiprocessing import set_sharing_strategy\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.datasets import CelebA\n",
    "from torchvision.transforms import ToTensor, CenterCrop, Resize, Compose, Normalize\n",
    "\n",
    "def marginal_prob_std(t, sigma):\n",
    "    t = torch.tensor(t, device=device)\n",
    "    return torch.sqrt((sigma ** (2 * t) - 1.) / 2. / math.log(sigma))\n",
    "def diffusion_coeff(t, sigma):\n",
    "    return torch.tensor(sigma ** t, device=device)\n",
    "\n",
    "\n",
    "sigma = 25.0  # @param {'type':'number'}-> sigma is a parameter that can be modified or adjusted.\n",
    "marginal_prob_std_fn = functools.partial(marginal_prob_std, sigma=sigma)\n",
    "diffusion_coeff_fn = functools.partial(diffusion_coeff, sigma=sigma)\n",
    "    \n",
    "def Euler_Maruyama_sampler(score_model,\n",
    "                           marginal_prob_std,\n",
    "                           diffusion_coeff,\n",
    "                           batch_size=64,\n",
    "                           x_shape=(1, 28, 28),\n",
    "                           num_steps=500,\n",
    "                           device='cuda',\n",
    "                           eps=1e-3,\n",
    "                           y=None):\n",
    "    t = torch.ones(batch_size, device=device)\n",
    "    init_x = torch.randn(batch_size, *x_shape, device=device) \\\n",
    "             * marginal_prob_std(t)[:, None, None, None]\n",
    "    time_steps = torch.linspace(1., eps, num_steps, device=device)\n",
    "    step_size = time_steps[0] - time_steps[1]\n",
    "    x = init_x\n",
    "    with torch.no_grad():\n",
    "        for time_step in tqdm(time_steps):\n",
    "            batch_time_step = torch.ones(batch_size, device=device) * time_step\n",
    "            g = diffusion_coeff(batch_time_step)\n",
    "            mean_x = x + (g ** 2)[:, None, None, None] * score_model(x, batch_time_step, cond=y, output_dict=False) * step_size\n",
    "            x = mean_x + torch.sqrt(step_size) * g[:, None, None, None] * torch.randn_like(x)\n",
    "            # Do not include any noise in the last sampling step.\n",
    "    return mean_x\n",
    "    \n",
    "# Load the trained model and embedding\n",
    "device = 'cuda'\n",
    "unet_face = UNet_SD(in_channels=3,\n",
    "                    base_channels=128,\n",
    "                    time_emb_dim=256,\n",
    "                    context_dim=256,\n",
    "                    multipliers=(1, 1, 2),\n",
    "                    attn_levels=(1, 2, ),\n",
    "                    nResAttn_block=1).to(device)\n",
    "\n",
    "cond_embed = nn.Embedding(40 + 1, 256, padding_idx=40).to(device)\n",
    "\n",
    "unet_face.load_state_dict(torch.load('fort2/ckpt_unet_SD_face.pth'))\n",
    "cond_embed.load_state_dict(torch.load('fort2/ckpt_unet_SD_face_cond_embed.pth'))\n",
    "\n",
    "# Define specific labels (replace with your desired attributes)\n",
    "# Example: Let's say 0 - '5_o_Clock_Shadow', 1 - 'Arched_Eyebrows', ..., 39 - 'Wearing_Necktie'\n",
    "# Here we assume 'smiling' is the 31st attribute, and 'wearing glasses' is the 15th attribute.\n",
    "# modify this according to the specific attributes you have.\n",
    "desired_labels = torch.zeros(64, 40, dtype=torch.int)  # Batch of 64 samples\n",
    "desired_labels[:, 31] = 1  # Set 'smiling' attribute to True\n",
    "desired_labels[:, 15] = 1  # Set 'wearing glasses' attribute to True\n",
    "\n",
    "# Embed the labels\n",
    "y_emb = cond_embed(desired_labels.to(device))\n",
    "\n",
    "# Function to generate and visualize sample images\n",
    "def generate_and_visualize_samples(model, y_emb, device='cuda', num_samples=64, num_steps=250):\n",
    "    samples = Euler_Maruyama_sampler(model,\n",
    "                                     marginal_prob_std_fn,\n",
    "                                     diffusion_coeff_fn,\n",
    "                                     num_samples,\n",
    "                                     x_shape=(3, 32, 32),\n",
    "                                     num_steps=num_steps,\n",
    "                                     device=device,\n",
    "                                     y=y_emb)\n",
    "    \n",
    "    # Denormalize the samples\n",
    "    denormalize = Normalize([-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
    "                            [1/0.229, 1/0.224, 1/0.225])\n",
    "    samples = denormalize(samples).clamp(0.0, 1.0)\n",
    "    sample_grid = make_grid(samples, nrow=int(math.sqrt(num_samples)))\n",
    "    \n",
    "    # Visualize the samples\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(sample_grid.permute(1, 2, 0).cpu(), vmin=0., vmax=1.)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Generate and visualize samples with the desired labels\n",
    "generate_and_visualize_samples(unet_face, y_emb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8533a4b2-b898-47de-9d21-db3823925d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
